{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from spacy.lang.xx import MultiLanguage\n",
    "nlp = MultiLanguage()\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, load_model\n",
    "from keras_multi_head import MultiHeadAttention\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras_contrib.metrics import crf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path of file\n",
    "filename_test = \"../data/test/clear-sent-comb-with-label.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle file\n",
    "word2idx = pickle.load(open(\"../data/pickle_file/word2idx.pkl\",\"rb\"))\n",
    "char2idx = pickle.load(open(\"../data/pickle_file/char2idx.pkl\",\"rb\"))\n",
    "label2idx = pickle.load(open(\"../data/pickle_file/label2idx.pkl\",\"rb\"))\n",
    "idx2label = {v:k for k,v in label2idx.items()}\n",
    "\n",
    "maxwordlength = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"../model/ner_order_v5.h5\",\n",
    "                   custom_objects ={'CRF':CRF,\n",
    "                                   'crf_loss':crf_loss,\n",
    "                                   'crf_accuracy':crf_accuracy,\n",
    "                                   'MultiHeadAttention':MultiHeadAttention})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict data\n",
    "def predict(dataset):\n",
    "    predLabels = []\n",
    "    \n",
    "    for i, data in enumerate(dataset):\n",
    "        tokens, char= data\n",
    "        tokens = np.asarray([tokens])\n",
    "        char = np.asarray([char])\n",
    "        \n",
    "        pred = model.predict([tokens, char], verbose = False)[0]\n",
    "        predLabels.append([np.argmax(i) for i in pred])\n",
    "        \n",
    "    return predLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy model for each word/entity\n",
    "def checkaccuracy_word(predict_label,correct_label):\n",
    "    counter = 0\n",
    "    idx_wrong_pred = []\n",
    "    \n",
    "    for idx_sentence in tqdm(range(len(predict_label))):\n",
    "        for idx_word in range(len(predict_label[idx_sentence])):\n",
    "            if (predict_label[idx_sentence][idx_word]) == (correct_label[idx_sentence][idx_word]):\n",
    "                counter += 1\n",
    "            else :\n",
    "                idx_wrong_pred.append(idx_sentence)\n",
    "    return counter, idx_wrong_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check entity of word which is wrong prediction\n",
    "def checkaccuracy_entity(predict_label, correct_label):\n",
    "    correct_entity = []\n",
    "    wrong_entity = []\n",
    "    \n",
    "    for idx_sentence in tqdm(range(len(predict_label))):\n",
    "        for idx_word in range(len(predict_label[idx_sentence])):\n",
    "            if (predict_label[idx_sentence][idx_word]) == (correct_label[idx_sentence][idx_word]):\n",
    "                correct_entity.append(predict_label[idx_sentence][idx_word])\n",
    "            else :\n",
    "                wrong_entity.append(correct_label[idx_sentence][idx_word])\n",
    "    return correct_entity, wrong_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy model for each sentence/order\n",
    "def checkaccuracy_sent(predict_label, correct_label):\n",
    "    count = 0\n",
    "    for idx in range(len(predict_label)):\n",
    "        if predict_label[idx] == correct_label[idx] :\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_vector(text, word2Idx, char2Idx):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            text (str): Input sentence\n",
    "        Return:\n",
    "            A list consist of.\n",
    "            [0]: A list of Token's index in the sentence\n",
    "            [1]: A list of Casing condition of token in the sentence\n",
    "            [2]: A list of list of token's Characters pattern\n",
    "    \"\"\"\n",
    "    word_indices = []\n",
    "    char_indices = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        i = token.text\n",
    "        try:\n",
    "            word_indices.append(word2Idx[i])\n",
    "            unknown = False\n",
    "        except KeyError:\n",
    "            unknown = True #word_indices.append(word2Idx[\"UNK\"])\n",
    "        \n",
    "        if unknown == False:\n",
    "            tok = []\n",
    "            for j in i:\n",
    "                try:\n",
    "                    tok.append(char2Idx[j])\n",
    "                except KeyError:\n",
    "                    tok.append(char2Idx[\"UNK\"])\n",
    "            char_indices.append(pad_sequences([tok], maxlen=maxwordlength)[0])\n",
    "\n",
    "    return [word_indices, char_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split testing data\n",
    "data = []\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "with open(filename_test, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(line.rstrip())\n",
    "        sentences.append(line.rstrip().split(':')[0].lower())\n",
    "        labels.append(line.rstrip().split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ad2c4c1e864e65bc076a848dfaa033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=127466.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Do compute prediction on testing data\n",
    "predLabels = []\n",
    "\n",
    "for line in tqdm(sentences):\n",
    "    tmp = convert_to_vector(line, word2idx, char2idx)\n",
    "    ans = predict([tmp])[0]\n",
    "    ans = [idx2label[i] for i in ans]\n",
    "    predLabels.append(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctLabels = []\n",
    "\n",
    "for i in labels:\n",
    "    correctLabels.append(i.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdb656d99494174abaab9a3f687f6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=127466.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c6437947da4fe0b89dbb680f408833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=127466.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy per sentence : 62.505295529788334\n",
      "Accuracy per word : 90.46048642635328\n"
     ]
    }
   ],
   "source": [
    "# Performance on tes dataset\n",
    "total_word = 0\n",
    "for i in predLabels:\n",
    "    total_word += len(i)\n",
    "\n",
    "# Calculate Performance of model on data\n",
    "counter, idx_wrong_pred = checkaccuracy_word(predLabels, correctLabels)\n",
    "correct_entity, wrong_entity = checkaccuracy_entity(predLabels, correctLabels)\n",
    "count_sent = checkaccuracy_sent(predLabels, correctLabels)\n",
    "\n",
    "print(\"Accuracy per sentence :\", count_sent*100/len(predLabels))\n",
    "print(\"Accuracy per word :\", counter*100/total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc =  0.33\n",
      "numeric =  0.01\n",
      "o-brand =  0.14\n",
      "b-brand =  0.38\n",
      "uom =  0.05\n",
      "i-brand =  0.02\n",
      "color =  0.02\n",
      "brand =  0.0\n",
      "flavor =  0.02\n",
      "item =  0.03\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "total_wrong_entity = Counter(wrong_entity)\n",
    "name_wrong_entity = set(wrong_entity)\n",
    "\n",
    "for i in name_wrong_entity: \n",
    "    print (i+' = ', round(total_wrong_entity[i]/len(wrong_entity),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing use custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = 'gw beli abese kopi tai susu tiga saset lol emang oke'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do compute prediction on testing data\n",
    "predLabels = []\n",
    "\n",
    "tmp = convert_to_vector(input_data, word2idx, char2idx)\n",
    "ans = predict([tmp])[0]\n",
    "ans = [idx2label[i] for i in ans]\n",
    "predLabels.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['soo', 'brand', 'flavor', 'flavor', 'numeric', 'uom', 'eoo']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
