{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data Format and Add Sentence which have specific format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Before format (1 line) -> Abese Kopi Susu Sachet Satu Saset:BRAND DESCRIPTION DESCRIPTION UOM NUMERIC UOM\\n    \\n    After format (7 line) -> Abese,BRAND \\n                             Kopi,DESCRIPTION\\n                             Susu,DESCRIPTION\\n                             Sachet,UOM\\n                             Satu,NUMERIC\\n                             Saset,UOM\\n                             NaN\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Before format (1 line) -> Abese Kopi Susu Sachet Satu Saset:BRAND DESCRIPTION DESCRIPTION UOM NUMERIC UOM\n",
    "    \n",
    "    After format (7 line) -> Abese,BRAND \n",
    "                             Kopi,DESCRIPTION\n",
    "                             Susu,DESCRIPTION\n",
    "                             Sachet,UOM\n",
    "                             Satu,NUMERIC\n",
    "                             Saset,UOM\n",
    "                             NaN\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/clean/data-with-label.txt\"\n",
    "filename_kata = \"../data/clean/skrip_kata_warung_final.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(filename_kata)\n",
    "data = pd.read_csv(filename, sep=\":\", header=None, names=['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle(data)\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d373ce73c4704f7ead23965f088a161f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=261375.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Proses convert data format\n",
    "    Input : DataFrame berisi text dan label\n",
    "    Output : List (words, labels)\n",
    "\"\"\"\n",
    "words = []\n",
    "labels = []\n",
    "\n",
    "for idx in tqdm(range(len(data))):\n",
    "    length_words = len(data.loc[idx,'text'].split())\n",
    "    tokenize_words = data.loc[idx,'text'].split()\n",
    "    tokenize_labels = data.loc[idx,'label'].split()\n",
    "    \n",
    "    for i in range(length_words):\n",
    "        words.append(tokenize_words[i])\n",
    "        labels.append(tokenize_labels[i])\n",
    "    \n",
    "    words.append(np.nan)\n",
    "    labels.append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dictionary for entity and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = df.ITEM.dropna()\n",
    "brand = df.BRAND.dropna()\n",
    "b_brand = df['B-BRAND'].dropna()\n",
    "i_brand = df['I-BRAND'].dropna()\n",
    "o_brand = df['O-BRAND'].dropna()\n",
    "desc = df.DESCRIPTION.dropna()\n",
    "numeric = df.NUMERIC.dropna()\n",
    "conjunction = df.CONJUNCTION.dropna()\n",
    "uom = df.UOM.dropna()\n",
    "sop_trigger = df['SOP-TRIGGER'].dropna()\n",
    "unk = df.UNKNOWN.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_entity = {'item':item, 'brand':brand, 'b_brand':b_brand, 'i_brand':i_brand, 'o_brand':o_brand,\n",
    "               'desc':desc, 'numeric':numeric, 'conjunction':conjunction, 'uom':uom,\n",
    "               'sop_trigger':sop_trigger, 'unk':unk}\n",
    "\n",
    "dict_label = {'item':'ITEM', 'brand':'BRAND', 'b_brand':'B-BRAND', 'i_brand':'I-BRAND', 'o_brand':'O-BRAND',\n",
    "               'desc':'DESCRIPTION', 'numeric':'NUMERIC', 'conjunction':'CONJUNCTION', 'uom':'UOM',\n",
    "               'sop_trigger':'SOP-TRIGGER', 'unk':'UNKNOWN'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add sentence which have specific format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kalimat yang terdiri dari 1 kata\n",
    "\"\"\"\n",
    "\n",
    "## Sentences that only have 1 word\n",
    "sentence_one = ['item','brand','b_brand','i_brand','o_brand',\n",
    "                'desc','numeric','conjunction','uom','sop_trigger','unk']\n",
    "\n",
    "for entity in sentence_one:\n",
    "    for i in dict_entity[entity]:\n",
    "        words.append(i.lower())\n",
    "        labels.append(dict_label[entity])\n",
    "        words.append(np.nan)\n",
    "        labels.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kalimat yang terdiri dari 2 kata\n",
    "\"\"\"\n",
    "\n",
    "## Sentences that only have 2 word\n",
    "sentence_two = [['item','numeric'],['item','desc'],['brand','numeric'],['numeric','brand'],['b_brand','numeric']]\n",
    "\n",
    "for sentence in sentence_two:\n",
    "    for i in range(15000):\n",
    "        for entity in sentence:\n",
    "            words.append(random.choice(dict_entity[entity]).lower())\n",
    "            labels.append(dict_label[entity])\n",
    "        \n",
    "        words.append(np.nan)\n",
    "        labels.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kalimat yang terdiri dari 3 kata\n",
    "\"\"\"\n",
    "\n",
    "## Sentences that only have 3 word\n",
    "sentence_three = [['brand','desc','numeric'],['item','desc','numeric'],['item','numeric','uom'],\n",
    "                  ['brand','numeric','uom'],['brand','uom','numeric'],['unk','item','numeric'],\n",
    "                  ['numeric','brand','unk'],['b_brand','o_brand','numeric']]\n",
    "\n",
    "for sentence in sentence_three:\n",
    "    for i in range(15000):\n",
    "        for entity in sentence:\n",
    "            words.append(random.choice(dict_entity[entity]).lower())\n",
    "            labels.append(dict_label[entity])\n",
    "        \n",
    "        words.append(np.nan)\n",
    "        labels.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kalimat yang terdiri dari 4 kata\n",
    "\"\"\"\n",
    "\n",
    "## Sentences that only have 4 word\n",
    "sentence_four = [['brand','uom','numeric','uom'],['numeric','uom','brand','desc'],\n",
    "                 ['numeric','uom','brand','uom'],['desc','uom','numeric','uom'],\n",
    "                 ['item','b_brand','o_brand','numeric']]\n",
    "\n",
    "for sentence in sentence_four:\n",
    "    for i in range(15000):\n",
    "        for entity in sentence:\n",
    "            words.append(random.choice(dict_entity[entity]).lower())\n",
    "            labels.append(dict_label[entity])\n",
    "        \n",
    "        words.append(np.nan)\n",
    "        labels.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kalimat yang terdiri dari 5 kata\n",
    "\"\"\"\n",
    "\n",
    "## Sentences that only have 5 word\n",
    "sentence_five = [['numeric','uom','brand','uom','uom'],['numeric','uom','brand','desc','uom'],\n",
    "                 ['numeric','b_brand','o_brand','desc','uom']]\n",
    "\n",
    "for sentence in sentence_five:\n",
    "    for i in range(15000):\n",
    "        for entity in sentence:\n",
    "            words.append(random.choice(dict_entity[entity]).lower())\n",
    "            labels.append(dict_label[entity])\n",
    "        \n",
    "        words.append(np.nan)\n",
    "        labels.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kalimat yang terdiri dari 6 kata\n",
    "\"\"\"\n",
    "\n",
    "## Sentences that only have 6 word\n",
    "sentence_six = [['b_brand','o_brand','desc','uom','numeric','uom']]\n",
    "\n",
    "for sentence in sentence_six:\n",
    "    for i in range(15000):\n",
    "        for entity in sentence:\n",
    "            words.append(random.choice(dict_entity[entity]).lower())\n",
    "            labels.append(dict_label[entity])\n",
    "        \n",
    "        words.append(np.nan)\n",
    "        labels.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add more data for B-I-O\n",
    "\"\"\"\n",
    "\n",
    "sentence_add = [['b_brand','o_brand','numeric'],['item','b_brand','o_brand','numeric'],\n",
    "                  ['b_brand','o_brand','desc','numeric'],['numeric','b_brand','o_brand','desc','uom'],\n",
    "                  ['item','b_brand','i_brand','o_brand','desc','numeric','uom'],\n",
    "                  ['numeric','b_brand','i_brand','o_brand'],['numeric','b_brand','i_brand','o_brand','desc']]\n",
    "\n",
    "for sentence in sentence_add:\n",
    "    for i in range(25000):\n",
    "        for entity in sentence:\n",
    "            words.append(random.choice(dict_entity[entity]).lower())\n",
    "            labels.append(dict_label[entity])\n",
    "        \n",
    "        words.append(np.nan)\n",
    "        labels.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 2 list to dataframe\n",
    "df_sentences = pd.DataFrame(list(zip(words, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower token\n",
    "lower_token = []\n",
    "\n",
    "for i in df_sentences[0]:\n",
    "    if type(i) != float:\n",
    "        lower_token.append(i.lower())\n",
    "    else:\n",
    "        lower_token.append(i)\n",
    "\n",
    "df_sentences[0] = lower_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences.to_csv('../data/clean/dataset.csv', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
