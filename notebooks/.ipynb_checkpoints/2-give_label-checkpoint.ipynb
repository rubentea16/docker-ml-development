{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path of file\n",
    "filename_test = \"../data/clean/data.txt\" ## file which want to give label [train data/test data]\n",
    "filename_vocab = \"../data/clean/skrip_kata_warung_final.xlsx\"\n",
    "filename_replace_word = \"../data/clean/replace quantity.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create list of vocabulary, list of vocabulary+label\n",
    "df_vocab = pd.read_excel(filename_vocab)\n",
    "\n",
    "list_vocab = []\n",
    "list_vocab_label = []\n",
    "\n",
    "for col in df_vocab.columns:\n",
    "    for val in df_vocab[col].dropna():\n",
    "        list_vocab.append(val.lower())\n",
    "        list_vocab_label.append(val.lower()+':'+col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load testing data\n",
    "data = []\n",
    "with open(filename_test, encoding='utf-8') as f:\n",
    "    for i in f:\n",
    "        data.append(i.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a33e4735bc46d6b194cdfcc2c7118a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=261375.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Replace 'Sesachet' -> 'satu sachet'\n",
    "df_replace_word = pd.read_excel(filename_replace_word)\n",
    "dict_replace_word = pd.Series(df_replace_word.after.values, index=df_replace_word.before).to_dict()\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for line in tqdm(data):\n",
    "    check_status = 0\n",
    "    for key, val in dict_replace_word.items():\n",
    "        if key in line:\n",
    "            check_status = 1\n",
    "            new_data.append(line.replace(key,val))\n",
    "    if check_status != 1:\n",
    "        new_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72533fac81147819b91a25651e8e890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=261375.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "out_of_vocab = []\n",
    "\n",
    "for i in tqdm(new_data):\n",
    "    list_label = []\n",
    "    tokenize_word = i.split()\n",
    "    for token in tokenize_word :\n",
    "        if token.lower() in list_vocab:\n",
    "            if ((token.lower() == 'kopi') or (token.lower() == 'susu')) and (tokenize_word.index(token) == 0):\n",
    "                list_label.append('ITEM')\n",
    "            elif (token.lower() == 'delapan') and ('Tujuh' not in i):\n",
    "                list_label.append('NUMERIC')\n",
    "            elif (token.lower() == 'cap') and ('Lang' not in i):\n",
    "                list_label.append('UOM')\n",
    "            elif (token.lower() == 'kopi') or (token.lower() == 'susu'):\n",
    "                list_label.append('DESCRIPTION')\n",
    "            elif ('Dua Belas' in i) and ((token.lower() == 'dua') or (token.lower() == 'belas')):\n",
    "                list_label.append('DESCRIPTION')\n",
    "            elif ('Enam Belas' in i) and ((token.lower() == 'enam') or (token.lower() == 'belas')):\n",
    "                list_label.append('DESCRIPTION')\n",
    "            elif ('Dua Puluh' in i) and ((token.lower() == 'dua') or (token.lower() == 'puluh')):\n",
    "                list_label.append('DESCRIPTION')\n",
    "            elif (('Tujuh Enam' in i)or('Tujuh Puluh Enam' in i)) and ((token.lower()=='tujuh')or(token.lower()=='puluh')or(token.lower()=='enam')):\n",
    "                list_label.append('DESCRIPTION')\n",
    "            elif (token.lower() == 'bos') and ('Nutri' not in i):\n",
    "                list_label.append('SOP-TRIGGER')\n",
    "            elif (token.lower() == 'dua') and ('MX' not in i):\n",
    "                list_label.append('NUMERIC')\n",
    "            elif (token.lower() == 'tiga') and ('Kaki' not in i):\n",
    "                list_label.append('NUMERIC')\n",
    "            elif (token.lower() == 'wan') and ('Yusi' not in i):\n",
    "                list_label.append('NUMERIC')\n",
    "            elif (token.lower() == 'tujuh') and ('Delapan' not in i):\n",
    "                list_label.append('NUMERIC')\n",
    "            elif ((token.lower() == 'ekstra') or (token.lower() == 'ektra')) and (tokenize_word.index(token) == 1):\n",
    "                list_label.append('DESCRIPTION')\n",
    "            else :\n",
    "                idx_vocab = list_vocab.index(token.lower())\n",
    "                list_label.append(list_vocab_label[idx_vocab].split(':')[1])\n",
    "        else :\n",
    "            out_of_vocab.append(token)\n",
    "    result.append(i+':'+(' '.join(list_label)))\n",
    "\n",
    "out_of_vocab = set(out_of_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2c106e685e449792e5d6fe4fadb49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=261375.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../data/clean/data-with-label.txt','w') as outfile:\n",
    "    for line in tqdm(result):\n",
    "        outfile.write('%s\\n' % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abese Kopi Susu Sachet Satu Saset:BRAND DESCRIPTION DESCRIPTION UOM NUMERIC UOM',\n",
       " 'Abese Kopi Susu Sachet Atu Saset:BRAND DESCRIPTION DESCRIPTION UOM NUMERIC UOM',\n",
       " 'Abese Kopi Susu Sachet Tu Saset:BRAND DESCRIPTION DESCRIPTION UOM NUMERIC UOM',\n",
       " 'Abese Kopi Susu Sachet Dua Saset:BRAND DESCRIPTION DESCRIPTION UOM NUMERIC UOM',\n",
       " 'Abese Kopi Susu Sachet Dobel Saset:BRAND DESCRIPTION DESCRIPTION UOM NUMERIC UOM']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261375"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
